{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision.models.vgg import VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler                                                                                                                                                                                       \n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16_model(nn.Module):\n",
    "    def __init__(self, numClasses=6):\n",
    "        super(VGG16_model, self).__init__()\n",
    "        self.vgg16 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, 3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, 3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, 3),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 256, 3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, 3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, 3),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 512, 3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, 3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, 3),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, 3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, 3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, 3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, numClasses)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.vgg16(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "epochs     = 200  #500\n",
    "lr         = 1e-4\n",
    "momentum   = 0\n",
    "w_decay    = 1e-5\n",
    "step_size  = 50\n",
    "gamma      = 0.5\n",
    "model_use  = \"aoi_model\" \n",
    "\n",
    "n_class = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"./aoi/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FullPath = os.getcwd()\n",
    "data_dir  = os.path.join(FullPath + \"/aoi/train_images\")\n",
    "model_dir = os.path.join(FullPath + \"/models\", model_use)\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composed = transform.Compose([transform.Resize((224,224)), #  resize\n",
    "                               #transform.RandomCrop(300), # random crop\n",
    "                               transform.ToTensor(),\n",
    "                               transform.Normalize(mean=[0.5],  # normalize\n",
    "                                                    std=[0.5])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_images = []\n",
    "for i in range(data.shape[0]):\n",
    "    images_path = (os.path.join(data_dir + \"/\" +data.ID[i]))\n",
    "    images = Image.open(images_path)\n",
    "    images = composed(images)\n",
    "    data_images.append(np.array(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data):\n",
    "    tra = []\n",
    "    #val = []\n",
    "    for i, d in enumerate(data):\n",
    "        #if i <= 2022:\n",
    "        tra.append(d)\n",
    "        #else:\n",
    "        #    val.append(d)\n",
    "    return tra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tra_data = zip(data_images, np.array(data.Label))\n",
    "tra = split_data(tra_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tra_loader = DataLoader(tra,shuffle=True,batch_size = 4, num_workers = 0)\n",
    "#val_loader = DataLoader(val,num_workers = 0,batch_size = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "num_gpu = list(range(torch.cuda.device_count()))\n",
    "\n",
    "model = VGG16_model()\n",
    "\n",
    "if use_gpu:\n",
    "    ts = time.time()\n",
    "    model = model.cuda()\n",
    "    print(\"Finish cuda loading, time elapsed {}\".format(time.time() - ts))\n",
    "else:\n",
    "#     nn.DataParallel(fcn_model)\n",
    "    print(\"Use CPU to train.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)\n",
    "params = list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.RMSprop(model.parameters(), lr = lr, momentum = momentum, weight_decay = w_decay)\n",
    "# decay LR by a factor of 0.5 every step_size = 50 epochs\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size = step_size, gamma = gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        scheduler.step()\n",
    "        \n",
    "        configs    = \"vgg16_{}_batch{}_epoch{}_RMSprop_lr{}\"\\\n",
    "            .format(model_use, batch_size, epoch, lr)\n",
    "        model_path = os.path.join(model_dir, configs)\n",
    "        \n",
    "        ts = time.time()\n",
    "        for iter, (data, label) in enumerate(tra_loader):\n",
    "            optimizer.zero_grad()\n",
    "            #data = data.unsqueeze(1)\n",
    "            if use_gpu:\n",
    "                inputs = Variable(data.cuda())\n",
    "                labels = Variable(label.cuda())\n",
    "            else:\n",
    "                inputs, labels = Variable(data), Variable(label)\n",
    "            inputs = inputs.float()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if iter % 1 == 0:\n",
    "                print(\"epoch{}, iter{}, loss: {}\".format(epoch+1, iter, loss.item()))\n",
    "        \n",
    "        print(\"Finish epoch {}, time elapsed {}\".format(epoch+1, time.time() - ts))\n",
    "        if epoch % 1 == 0:\n",
    "            torch.save(model.state_dict(),model_path + '.pkl')\n",
    "\n",
    "        #val(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16_model()\n",
    "test = pd.read_csv(\"./aoi/test.csv\")\n",
    "state_dict = torch.load(os.path.join(model_dir, \"vgg16_aoi_model_batch4_epoch149_RMSprop_lr0.0001.pkl\"), map_location='cpu')\n",
    "model.load_state_dict(state_dict)\n",
    " \n",
    "test_dir  = os.path.join(FullPath + \"/aoi/test_images\")\n",
    "test_images = []\n",
    "    \n",
    "for i in range(test.shape[0]):\n",
    "    images_path = (os.path.join(test_dir + \"/\" +test.ID[i]))\n",
    "    images = Image.open(images_path)\n",
    "    images = composed(images)\n",
    "    test_images.append(np.array(images))\n",
    "    \n",
    "if use_gpu:\n",
    "    ts = time.time()\n",
    "    model = model.cuda()\n",
    "    print(\"Finish cuda loading, time elapsed {}\".format(time.time() - ts))\n",
    "else:\n",
    "#     nn.DataParallel(fcn_model)\n",
    "    print(\"Use CPU to train.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_images,shuffle=False,batch_size = 4, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i,data in enumerate(test_loader):\n",
    "    if use_gpu:\n",
    "        inputs = Variable(data.cuda())\n",
    "    else:\n",
    "        inputs, labels = Variable(data)\n",
    "    outputs = model(inputs)\n",
    "    outputs = outputs.data.cpu().numpy()\n",
    "    result.append(np.argmax(outputs, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[2535]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "for i in range(2535):\n",
    "    label.append(result[i][0])\n",
    "    label.append(result[i][1])\n",
    "    label.append(result[i][2])\n",
    "    label.append(result[i][3])\n",
    "label.append(result[2535][0])\n",
    "label.append(result[2535][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.Label = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv(os.path.join(FullPath + \"/aoi/Result4.csv\",index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
