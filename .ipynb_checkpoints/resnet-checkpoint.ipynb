{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler                                                                                                                                                                                       \n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, inchannel, outchannel, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.left = nn.Sequential(\n",
    "            nn.Conv2d(inchannel, outchannel, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(outchannel, outchannel, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel)\n",
    "        )\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or inchannel != outchannel:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(inchannel, outchannel, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(outchannel)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.left(x)\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, ResidualBlock, num_classes=6):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inchannel = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.layer1 = self.make_layer(ResidualBlock, 64,  2, stride=1)\n",
    "        self.layer2 = self.make_layer(ResidualBlock, 128, 2, stride=2)\n",
    "        self.layer3 = self.make_layer(ResidualBlock, 256, 2, stride=2)\n",
    "        self.layer4 = self.make_layer(ResidualBlock, 512, 2, stride=2)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def make_layer(self, block, channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)   #strides=[1,1]\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.inchannel, channels, stride))\n",
    "            self.inchannel = channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18():\n",
    "\n",
    "    return ResNet(ResidualBlock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数设置\n",
    "EPOCH = 10   #遍历数据集次数\n",
    "pre_epoch = 0  # 定义已经遍历数据集的次数\n",
    "BATCH_SIZE = 4      #批处理尺寸(batch_size)\n",
    "LR = 0.01        #学习率\n",
    "model_use  = \"aoi_model\" \n",
    "\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"./aoi/train.csv\")\n",
    "\n",
    "FullPath = os.getcwd()\n",
    "data_dir  = os.path.join(FullPath + \"/aoi/train_images\")\n",
    "model_dir = os.path.join(FullPath + \"/models\", model_use)\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),  #先四周填充0，在吧图像随机裁剪成32*32\n",
    "    transforms.RandomHorizontalFlip(),  #图像一半的概率翻转，一半的概率不翻转\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5],std=[0.5]), # normalize\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5],std=[0.5]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_images = []\n",
    "for i in range(data.shape[0]):\n",
    "    images_path = (os.path.join(data_dir + \"/\" +data.ID[i]))\n",
    "    images = Image.open(images_path)\n",
    "    images = transform_train(images)\n",
    "    data_images.append(np.array(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data):\n",
    "    tra = []\n",
    "    #val = []\n",
    "    for i, d in enumerate(data):\n",
    "        #if i <= 2022:\n",
    "        tra.append(d)\n",
    "        #else:\n",
    "        #    val.append(d)\n",
    "    return tra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tra_data = zip(data_images, np.array(data.Label))\n",
    "tra = split_data(tra_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tra_loader = DataLoader(tra,shuffle=True,batch_size = 4, num_workers = 2)\n",
    "#val_loader = DataLoader(val,num_workers = 0,batch_size = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('0', '1', '2', '3', '4', '5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "num_gpu = list(range(torch.cuda.device_count()))\n",
    "\n",
    "# 模型定义-ResNet\n",
    "net = ResNet18().to(device)\n",
    "\n",
    "if use_gpu:\n",
    "    ts = time.time()\n",
    "    model = net.cuda()\n",
    "    print(\"Finish cuda loading, time elapsed {}\".format(time.time() - ts))\n",
    "else:\n",
    "#     nn.DataParallel(fcn_model)\n",
    "    print(\"Use CPU to train.\")\n",
    "\n",
    "print(net)\n",
    "params = list(net.parameters())\n",
    "\n",
    "# 定义损失函数和优化方式\n",
    "criterion = nn.CrossEntropyLoss()  #损失函数为交叉熵，多用于多分类问题\n",
    "optimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4) #优化方式为mini-batch momentum-SGD，并采用L2正则化（权重衰减）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    best_acc = 85  #2 初始化best test accuracy\n",
    "    print(\"Start Training, Resnet-18!\")  # 定义遍历数据集的次数\n",
    "    \n",
    "    with open(\"acc.txt\", \"w\") as f:\n",
    "        with open(\"log.txt\", \"w\")as f2:\n",
    "            for epoch in range(pre_epoch, EPOCH):\n",
    "                configs    = \"resnet_{}_batch{}_epoch{}_RMSprop_lr{}\"\\\n",
    "                    .format(model_use, BATCH_SIZE, epoch, LR)\n",
    "                model_path = os.path.join(model_dir, configs)\n",
    "                print('\\nEpoch: %d' % (epoch + 1))\n",
    "                net.train()\n",
    "                sum_loss = 0.0\n",
    "                correct = 0.0\n",
    "                total = 0.0\n",
    "                for i, data in enumerate(tra_loader, 0):\n",
    "                    # 准备数据\n",
    "                    length = len(tra_loader)\n",
    "                    inputs, labels = data\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward + backward\n",
    "                    outputs = net(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    # 每训练1个batch打印一次loss和准确率\n",
    "                    sum_loss += loss.item()\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += predicted.eq(labels.data).cpu().sum()\n",
    "                    print('[epoch:%d, iter:%d] Loss: %.03f | Acc: %.3f%% '\n",
    "                          % (epoch + 1, (i + 1 + epoch * length), sum_loss / (i + 1), 100. * correct / total))\n",
    "                    f2.write('%03d  %05d |Loss: %.03f | Acc: %.3f%% '\n",
    "                          % (epoch + 1, (i + 1 + epoch * length), sum_loss / (i + 1), 100. * correct / total))\n",
    "                    f2.write('\\n')\n",
    "                    f2.flush()\n",
    "                if epoch % 1 == 0:\n",
    "                    torch.save(model.state_dict(),model_path + '.pkl')\n",
    "            print(\"Training Finished, TotalEPOCH=%d\" % EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ResNet18().to(device)\n",
    "\n",
    "test = pd.read_csv(\"./aoi/test.csv\")\n",
    "state_dict = torch.load(os.path.join(model_dir, \"resnet_aoi_model_batch4_epoch9_RMSprop_lr0.01.pkl\"), map_location='cpu')\n",
    "model.load_state_dict(state_dict)\n",
    " \n",
    "test_dir  = os.path.join(FullPath + \"/aoi/test_images\")\n",
    "test_images = []\n",
    "    \n",
    "for i in range(test.shape[0]):\n",
    "    images_path = (os.path.join(test_dir + \"/\" +test.ID[i]))\n",
    "    images = Image.open(images_path)\n",
    "    images = transform_test(images)\n",
    "    test_images.append(np.array(images))\n",
    "    \n",
    "if use_gpu:\n",
    "    ts = time.time()\n",
    "    model = net.cuda()\n",
    "    print(\"Finish cuda loading, time elapsed {}\".format(time.time() - ts))\n",
    "else:\n",
    "#     nn.DataParallel(fcn_model)\n",
    "    print(\"Use CPU to train.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_images,shuffle=False,batch_size = 4, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "for i,data in enumerate(test_loader):\n",
    "    if use_gpu:\n",
    "        inputs = Variable(data.cuda())\n",
    "    else:\n",
    "        inputs, labels = Variable(data)\n",
    "    outputs = net(inputs)\n",
    "    outputs = outputs.data.cpu().numpy()\n",
    "    result.append(np.argmax(outputs, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
